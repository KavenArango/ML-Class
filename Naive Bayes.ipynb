{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability, Conditional Probability, Bayes' Theorem\n",
    "## Conditional Probability\n",
    "**Conditional Probability is defined as the probability of an event ( A ), given that another ( B ) has already occurred.**\n",
    "\n",
    "If events A and B are not independent, then the probability of the intersection of A and B (the probability that both P(B|A) = vents occur) is defined by \n",
    "P(A and B) = P(A)P(B|A).\n",
    "\n",
    "From this definition, the conditional probability P(B|A) is easily obtained by dividing by P(A):\n",
    "\n",
    "**P(B|A) = P(B and A) / P(A)**\n",
    "\n",
    "In the Predictive Analytics section we will learn a very widely used **Classification** algorithm called the **Naive Bayes Classifiaction Algorithm**.\n",
    "\n",
    "It is a Machine Learning algorithm that is often used in data sets with multiple attributes. It is very easy to calculate and hence is often used to classify things in real time, such as \"if an email containing a set of key words is classified as spam\", \"a newly published article belongs to a class of articles\", \"if an insurance claim, just submitted is real or fraud\" etc.\n",
    "\n",
    "The **Bayes** part of the name comes from Thomas Bayes, the inventor of the foundational Bayes' theorem and the **Naive** part of the name comes from the assumption that the factors guiding the occurrance of an event are **independent** of each other, even though in real life, they may not be so (a somewhat **naive** assumption). However, this algorithm produces very good/reliable results and is widely used.\n",
    "\n",
    "\n",
    "\n",
    "## Bayes' Theorem\n",
    "Bayes' Theorem (also called Bayes' Law or Bayes' Formula) is stated as\n",
    "\n",
    "***Probability of an event A given that an event B has occurred, is equal to the probability of B given A has occurred multiplied by the probability of A given B has occurred divided by the probability of B***\n",
    "\n",
    "***P(A|B) = (P(B|A) X P(A))/P(B)***\n",
    "\n",
    "where\n",
    "\n",
    "P(A|B) = Probability of event A given the event B has occurred\n",
    "\n",
    "P(B|A) = Probability of event B given the event A has occurred\n",
    "\n",
    "P(A), P(B) = Probabilities of event A and B respectively\n",
    "\n",
    "### Commonly used terms in Bayesian Classification\n",
    "A is called the **Proposition** and B is called the **Evidence**\n",
    "\n",
    "P(A) is called the **Prior Probability of Proposition** and P(B) is called the **Prior probability of Evidence**\n",
    "\n",
    "P(A|B) is called the **Posterior**\n",
    "\n",
    "P(B|A) is called the **Likelyhood**\n",
    "\n",
    "\n",
    "In other words\n",
    "\n",
    "***Posterior = (Likelihood X Prior Probability of Proposition)/Prior Probability of Evidence***\n",
    "\n",
    "### Bayesian Theorem as applied to Naive Bayes Algorithm\n",
    "In Machine Learning classification there are multiple clesses C1, C2, C3...and each class with multiple features x1, x2, x3...(e.g. an insurance claim is in class 'Valid' or 'Fraud' and each claim has features such as 'amount of claim', 'doctor submitting the claim', 'amount of the claim', 'frequency of high value claim for same treatment by the same doctor' etc.). The aim of the algorithm is to determine the **Conditional Probability** of an object (an insurance claim) with features x1, x2,...xn belonging to a class Ci.\n",
    "\n",
    "We will learn Bayesin Classification and it's calculation (using Python) in much more details in the **Predictive Analytics** section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=sjUDlJfdnKM.\n",
    "\n",
    "https://www.youtube.com/watch?v=CPqOCI0ahss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as mth\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing K_Mean Clustering, Naive Bayes and Logistic Regression using Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.feature_names\n",
    "iris.data\n",
    "iris.target_names\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal Length</th>\n",
       "      <th>Sepal Width</th>\n",
       "      <th>Petal Length</th>\n",
       "      <th>Petal Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sepal Length  Sepal Width  Petal Length  Petal Width\n",
       "0            5.1          3.5           1.4          0.2\n",
       "1            4.9          3.0           1.4          0.2\n",
       "2            4.7          3.2           1.3          0.2\n",
       "3            4.6          3.1           1.5          0.2\n",
       "4            5.0          3.6           1.4          0.2\n",
       "5            5.4          3.9           1.7          0.4\n",
       "6            4.6          3.4           1.4          0.3\n",
       "7            5.0          3.4           1.5          0.2\n",
       "8            4.4          2.9           1.4          0.2\n",
       "9            4.9          3.1           1.5          0.1\n",
       "10           5.4          3.7           1.5          0.2\n",
       "11           4.8          3.4           1.6          0.2\n",
       "12           4.8          3.0           1.4          0.1\n",
       "13           4.3          3.0           1.1          0.1\n",
       "14           5.8          4.0           1.2          0.2\n",
       "15           5.7          4.4           1.5          0.4\n",
       "16           5.4          3.9           1.3          0.4\n",
       "17           5.1          3.5           1.4          0.3\n",
       "18           5.7          3.8           1.7          0.3\n",
       "19           5.1          3.8           1.5          0.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(iris.data)\n",
    "iris_df.columns = ['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width']\n",
    "iris_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0\n",
       "5  0\n",
       "6  0\n",
       "7  0\n",
       "8  0\n",
       "9  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "140  2\n",
       "141  2\n",
       "142  2\n",
       "143  2\n",
       "144  2\n",
       "145  2\n",
       "146  2\n",
       "147  2\n",
       "148  2\n",
       "149  2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "30   0\n",
       "31   0\n",
       "32   0\n",
       "33   0\n",
       "34   0\n",
       "..  ..\n",
       "100  2\n",
       "101  2\n",
       "102  2\n",
       "103  2\n",
       "104  2\n",
       "\n",
       "[75 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df1 = pd.DataFrame(iris.target)\n",
    "iris_df1.head(10)\n",
    "iris_df1.tail(10)\n",
    "iris_df1[30:105]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using K-Mean Clustering\n",
    "\n",
    "## Defintions of \"Accuracy\", \"Precision\" and \"Recall\" scores of the prediction of a model\n",
    "\n",
    "### Accuracy = Number of correct prediction / Total Number of Predition\n",
    "\n",
    "### Precision = True Positive / (True Positive + False Positive)\n",
    "\n",
    "### Recall = True Positive / (True Positive + False Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 2 2 0 2 2 2 2\n",
      " 2 2 0 0 2 2 2 2 0 2 0 2 0 2 2 0 0 2 2 2 2 2 0 2 2 2 2 0 2 2 2 0 2 2 2 0 2\n",
      " 2 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        50\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.95      0.72      0.82        50\n",
      "\n",
      "    accuracy                           0.24       150\n",
      "   macro avg       0.32      0.24      0.27       150\n",
      "weighted avg       0.32      0.24      0.27       150\n",
      "\n",
      "[[ 0 50  0]\n",
      " [48  0  2]\n",
      " [14  0 36]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmodel = kmeans.fit(iris.data)\n",
    "expected = iris.target\n",
    "#predicted = kmodel.labels_\n",
    "predicted = kmodel.predict(iris.data)\n",
    "print('======>', predicted)\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(expected, kmodel.labels_))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using Gaussian Naive Bayes Model\n",
    "\n",
    "## Defintions of \"Accuracy\", \"Precision\" and \"Recall\" scores of the prediction of a model\n",
    "\n",
    "### Accuracy = Number of correct prediction / Total Number of Predition\n",
    "\n",
    "### Precision = True Positive / (True Positive + False Positive)\n",
    "\n",
    "### Recall = True Positive / (True Positive + False Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_target = pd.DataFrame(iris.target)\n",
    "iris_target.columns = ['Target Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbmodel = GaussianNB()\n",
    "nbmodel.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = iris.target\n",
    "predicted = nbmodel.predict(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.94      0.94      0.94        50\n",
      "           2       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.96       150\n",
      "   macro avg       0.96      0.96      0.96       150\n",
      "weighted avg       0.96      0.96      0.96       150\n",
      "\n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using  Multi-factors Logistic Regression\n",
    "\n",
    "## Defintions of \"Accuracy\", \"Precision\" and \"Recall\" scores of the prediction of a model\n",
    "\n",
    "### Accuracy = Number of correct prediction / Total Number of Predition\n",
    "\n",
    "### Precision = True Positive / (True Positive + False Positive)\n",
    "\n",
    "### Recall = True Positive / (True Positive + False Negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "#print(metrics.classification_report(expected, predicted))\n",
    "#print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utpal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utpal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Result ==================\n",
      "++++++++++++++++ Actual/Expected ++++++++++++++++++\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "++++++++++++++ Predicted ++++++++++++++++++++++++++\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "=============== Model Performance Results ===========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.98      0.90      0.94        50\n",
      "           2       0.91      0.98      0.94        50\n",
      "\n",
      "    accuracy                           0.96       150\n",
      "   macro avg       0.96      0.96      0.96       150\n",
      "weighted avg       0.96      0.96      0.96       150\n",
      "\n",
      "============ Model Confusion Matrix ===========\n",
      "[[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  1 49]]\n",
      "=============== Model Accuracy ==============\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(iris.data, iris.target)\n",
    "#print(lr_model)\n",
    "# make predictions\n",
    "expected = iris.target\n",
    "predicted = lr_model.predict(iris.data)\n",
    "\n",
    "print('================ Result ==================')\n",
    "print('++++++++++++++++ Actual/Expected ++++++++++++++++++')\n",
    "print(expected)\n",
    "print('++++++++++++++ Predicted ++++++++++++++++++++++++++')\n",
    "print(predicted)\n",
    "# summarize the fit of the model\n",
    "print('=============== Model Performance Results ===========')\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print('============ Model Confusion Matrix ===========')\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print('=============== Model Accuracy ==============')\n",
    "print(metrics.accuracy_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using Naive Bayes and Multi-Class Regression classifiers Native Indian Diabetes data sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defintions of \"Accuracy\", \"Precision\" and \"Recall\" scores of the prediction of a model\n",
    "\n",
    "### Accuracy = Number of correct prediction / Total Number of Predition\n",
    "\n",
    "### Precision = True Positive / (True Positive + False Positive)\n",
    "\n",
    "### Recall = True Positive / (True Positive + False Negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"c:/users/utpal/desktop/Regr_data_set/pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodP</th>\n",
       "      <th>SkinThick</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pregnancies  Glucose  BloodP  SkinThick  Insulin   BMI  \\\n",
       "0             6      148      72         35        0  33.6   \n",
       "1             1       85      66         29        0  26.6   \n",
       "2             8      183      64          0        0  23.3   \n",
       "3             1       89      66         23       94  28.1   \n",
       "4             0      137      40         35      168  43.1   \n",
       "5             5      116      74          0        0  25.6   \n",
       "6             3       78      50         32       88  31.0   \n",
       "7            10      115       0          0        0  35.3   \n",
       "8             2      197      70         45      543  30.5   \n",
       "9             8      125      96          0        0   0.0   \n",
       "10            4      110      92          0        0  37.6   \n",
       "11           10      168      74          0        0  38.0   \n",
       "12           10      139      80          0        0  27.1   \n",
       "13            1      189      60         23      846  30.1   \n",
       "14            5      166      72         19      175  25.8   \n",
       "15            7      100       0          0        0  30.0   \n",
       "16            0      118      84         47      230  45.8   \n",
       "17            7      107      74          0        0  29.6   \n",
       "18            1      103      30         38       83  43.3   \n",
       "19            1      115      70         30       96  34.6   \n",
       "\n",
       "    DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                      0.627   50        1  \n",
       "1                      0.351   31        0  \n",
       "2                      0.672   32        1  \n",
       "3                      0.167   21        0  \n",
       "4                      2.288   33        1  \n",
       "5                      0.201   30        0  \n",
       "6                      0.248   26        1  \n",
       "7                      0.134   29        0  \n",
       "8                      0.158   53        1  \n",
       "9                      0.232   54        1  \n",
       "10                     0.191   30        0  \n",
       "11                     0.537   34        1  \n",
       "12                     1.441   57        0  \n",
       "13                     0.398   59        1  \n",
       "14                     0.587   51        1  \n",
       "15                     0.484   32        1  \n",
       "16                     0.551   31        1  \n",
       "17                     0.254   31        1  \n",
       "18                     0.183   33        0  \n",
       "19                     0.529   32        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodP</th>\n",
       "      <th>SkinThick</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose      BloodP   SkinThick     Insulin  \\\n",
       "count   768.000000  768.000000  768.000000  768.000000  768.000000   \n",
       "mean      3.845052  120.894531   69.105469   20.536458   79.799479   \n",
       "std       3.369578   31.972618   19.355807   15.952218  115.244002   \n",
       "min       0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       1.000000   99.000000   62.000000    0.000000    0.000000   \n",
       "50%       3.000000  117.000000   72.000000   23.000000   30.500000   \n",
       "75%       6.000000  140.250000   80.000000   32.000000  127.250000   \n",
       "max      17.000000  199.000000  122.000000   99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as gnb\n",
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"]=15, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodP</th>\n",
       "      <th>SkinThick</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pregnancies  Glucose  BloodP  SkinThick  Insulin   BMI  \\\n",
       "0             6      148      72         35        0  33.6   \n",
       "1             1       85      66         29        0  26.6   \n",
       "2             8      183      64          0        0  23.3   \n",
       "3             1       89      66         23       94  28.1   \n",
       "4             0      137      40         35      168  43.1   \n",
       "5             5      116      74          0        0  25.6   \n",
       "6             3       78      50         32       88  31.0   \n",
       "8             2      197      70         45      543  30.5   \n",
       "10            4      110      92          0        0  37.6   \n",
       "11           10      168      74          0        0  38.0   \n",
       "12           10      139      80          0        0  27.1   \n",
       "13            1      189      60         23      846  30.1   \n",
       "14            5      166      72         19      175  25.8   \n",
       "16            0      118      84         47      230  45.8   \n",
       "17            7      107      74          0        0  29.6   \n",
       "18            1      103      30         38       83  43.3   \n",
       "19            1      115      70         30       96  34.6   \n",
       "20            3      126      88         41      235  39.3   \n",
       "21            8       99      84          0        0  35.4   \n",
       "22            7      196      90          0        0  39.8   \n",
       "\n",
       "    DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                      0.627   50        1  \n",
       "1                      0.351   31        0  \n",
       "2                      0.672   32        1  \n",
       "3                      0.167   21        0  \n",
       "4                      2.288   33        1  \n",
       "5                      0.201   30        0  \n",
       "6                      0.248   26        1  \n",
       "8                      0.158   53        1  \n",
       "10                     0.191   30        0  \n",
       "11                     0.537   34        1  \n",
       "12                     1.441   57        0  \n",
       "13                     0.398   59        1  \n",
       "14                     0.587   51        1  \n",
       "16                     0.551   31        1  \n",
       "17                     0.254   31        1  \n",
       "18                     0.183   33        0  \n",
       "19                     0.529   32        1  \n",
       "20                     0.704   27        0  \n",
       "21                     0.388   50        0  \n",
       "22                     0.451   41        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(724, 9)\n",
      "(543, 9)\n",
      "(181, 9)\n"
     ]
    }
   ],
   "source": [
    "data_mod = df0[(df0.BloodP != 0) & (df0.BMI != 0) & (df0.Glucose != 0)]\n",
    "data_mod.head(20)\n",
    "train, test = train_test_split(data_mod, test_size=0.25)\n",
    "print(data_mod.shape)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes  mean accuracy:  76.228 % std:  0.159 %\n",
      "Logistic Regression  mean accuracy:  75.699 % std:  0.092 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utpal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utpal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utpal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utpal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utpal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "features = ['Pregnancies', 'Glucose', 'BloodP', 'SkinThick', 'BMI', 'Age', 'Insulin', 'DiabetesPedigreeFunction']\n",
    "target = 'Outcome'\n",
    "\n",
    "classifiers = [gnb(), lr()]\n",
    "\n",
    "classifier_names = ['Gaussian Naive Bayes', 'Logistic Regression']\n",
    "\n",
    "for clf, clf_name in zip(classifiers, classifier_names):\n",
    "    cv_scores = cross_val_score(clf, train[features], train[target], cv=5)\n",
    "    \n",
    "    print(clf_name, ' mean accuracy: ', round(cv_scores.mean()*100, 3), '% std: ', round(cv_scores.var()*100, 3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the X and Y axes of the Heat Map\n",
    "\n",
    "### X-Axis = Prediction, 0 = True 1 = False\n",
    "### Y-Axis = Actual, 0 = True, 1 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy for Gaussian naive bayes classifier: 72.38 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79       119\n",
      "           1       0.59      0.61      0.60        62\n",
      "\n",
      "    accuracy                           0.72       181\n",
      "   macro avg       0.69      0.70      0.70       181\n",
      "weighted avg       0.73      0.72      0.72       181\n",
      "\n",
      "[[93 26]\n",
      " [24 38]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'confusion matrix for Gaussian naive bayes classifier')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x145fda10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_model_gnb = gnb().fit(train[features], train[target])\n",
    "y_hat_gnb = final_model_gnb.predict(test[features])\n",
    "\n",
    "print('test accuracy for Gaussian naive bayes classifier:', \\\n",
    "      round(accuracy_score(test[target], y_hat_gnb)*100, 2),'%')\n",
    "print(metrics.classification_report(test[target], y_hat_gnb))\n",
    "print(confusion_matrix(test[target], y_hat_gnb))\n",
    "plt.title('confusion matrix for Gaussian naive bayes classifier')\n",
    "sns.heatmap(confusion_matrix(test[target], y_hat_gnb), annot=True, cmap=\"YlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy for Logistic Regression classifier: 80.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utpal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'confusion matrix for Logistic Regression classifier')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86       119\n",
      "           1       0.80      0.56      0.66        62\n",
      "\n",
      "    accuracy                           0.80       181\n",
      "   macro avg       0.80      0.74      0.76       181\n",
      "weighted avg       0.80      0.80      0.79       181\n",
      "\n",
      "[[110   9]\n",
      " [ 27  35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x146aeeb0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_model_lr = lr().fit(train[features], train[target])\n",
    "y_hat_lr = final_model_lr.predict(test[features])\n",
    "\n",
    "print('test accuracy for Logistic Regression classifier:', \\\n",
    "      round(accuracy_score(test[target], y_hat_lr)*100, 2),'%')\n",
    "plt.title('confusion matrix for Logistic Regression classifier')\n",
    "print(metrics.classification_report(test[target], y_hat_lr))\n",
    "print(confusion_matrix(test[target], y_hat_lr))\n",
    "sns.heatmap(confusion_matrix(test[target], y_hat_lr), annot=True, cmap=\"YlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
